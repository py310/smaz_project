{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f20a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atass_config.ini']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from urllib.request import URLError, urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scipy.signal import find_peaks\n",
    "from utils import features_engeneering as fe\n",
    "from utils import modeling as md\n",
    "from utils.data_acquisition import *\n",
    "from utils.loop_funcs import *\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19cb2f5-a7da-498c-88c3-9a0f98849aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_adress = config[\"java_ip\"][\"market_data_ip\"]\n",
    "\n",
    "# Params\n",
    "symbols = [\n",
    "    \"AUDUSD\",\n",
    "    \"EURCHF\",\n",
    "    \"EURGBP\",\n",
    "    \"EURUSD\",\n",
    "    \"GBPCHF\",\n",
    "    \"NZDCAD\",\n",
    "    \"USDCAD\",\n",
    "    \"USDCHF\",\n",
    "]\n",
    "\n",
    "TIMEFRAME = \"H1\"\n",
    "freq = \"H\"\n",
    "\n",
    "start_date = \"2019-01-02\"\n",
    "MAX_INDICATOR_WINDOW = 1000\n",
    "OPTIMIZE_INDICATORS = True\n",
    "n_of_candles_to_add_to_target = 24\n",
    "relearn_duration, trade_duration, required_n_of_periods = \"36M\", 3, 4\n",
    "\n",
    "TICKERS_PATH = \"work_dir/\"\n",
    "query_id = \"rebalance\"\n",
    "ohlcv_file = \"ohlcv.csv\"\n",
    "target_file = \"target.csv\"\n",
    "indicators_file = \"indicators.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d269aea5-ae41-465c-abfd-57c4eb273b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Section: java_ip>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['java_ip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40633603-7248-459b-a843-81ef14119caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_models = {\n",
    "    \"PC\": [\n",
    "        \"AdaBoostClassifier\",\n",
    "        \"CatBoostClassifier\",\n",
    "        \"DecisionTreeClassifier\",\n",
    "        \"DummyClassifier\",\n",
    "        \"ExtraTreesClassifier\",\n",
    "        \"GaussianNB\",\n",
    "        \"GradientBoostingClassifier\",\n",
    "        \"KNeighborsClassifier\",\n",
    "        \"LGBMClassifier\",\n",
    "        \"LinearDiscriminantAnalysis\",\n",
    "        \"LogisticRegression\",\n",
    "        \"QuadraticDiscriminantAnalysis\",\n",
    "        \"RandomForestClassifier\",\n",
    "        \"RidgeClassifier\",\n",
    "        \"SGDClassifier\",\n",
    "        \"XGBClassifier\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "current_models = {\n",
    "    \"PC\": [\n",
    "        \"AdaBoostClassifier\",\n",
    "        \"CatBoostClassifier\",\n",
    "        \"DecisionTreeClassifier\",\n",
    "        \"DummyClassifier\",\n",
    "        \"ExtraTreesClassifier\",\n",
    "        \"GaussianNB\",\n",
    "        \"GradientBoostingClassifier\",\n",
    "        \"KNeighborsClassifier\",\n",
    "        \"LGBMClassifier\",\n",
    "        \"LinearDiscriminantAnalysis\",\n",
    "        \"LogisticRegression\",\n",
    "        \"QuadraticDiscriminantAnalysis\",\n",
    "        \"RandomForestClassifier\",\n",
    "        \"RidgeClassifier\",\n",
    "        \"SGDClassifier\",\n",
    "        \"XGBClassifier\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "possible_function_to_call_READ_MODELS = {\n",
    "    # \"AG\": md.AG_READ_MODELS,\n",
    "    \"PC\": md.PC_READ_MODELS,\n",
    "}\n",
    "\n",
    "possible_function_to_call_TRAIN = {\n",
    "    # \"AG\": md.AG_TRAIN,\n",
    "    \"PC\": md.PC_TRAIN\n",
    "}\n",
    "\n",
    "possible_function_to_call_TEST = {\n",
    "    # \"AG\": md.AG_TEST,\n",
    "    \"PC\": md.PC_TEST\n",
    "}\n",
    "\n",
    "current_libraries = list(current_models.keys())\n",
    "\n",
    "for library in current_libraries:\n",
    "    for model in current_models[library]:\n",
    "        if model not in possible_models[library]:\n",
    "            raise ValueError(f\"Wrong model name! You specified {model}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f5b6b-d60a-4448-9594-0b1e2b706e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE = {\n",
    "    \"OHLCV\": True,\n",
    "    \"TARGET\": True,\n",
    "    \"INDICATORS\": False,\n",
    "    \"MODELS_TRAIN\": False,\n",
    "    \"MODELS_TEST\": False,\n",
    "    \"TRADE\": False\n",
    "}\n",
    "# FORCE = {key: True for key in FORCE.keys()}\n",
    "SAVE = {\n",
    "    \"OHLCV\": True,\n",
    "    \"TARGET\": True,\n",
    "    \"INDICATORS\": True,\n",
    "    \"MODELS\": True,\n",
    "    \"PREDICTS\": True,\n",
    "    \"PORTFOLIOS\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e7970b-e1e2-4636-b3c6-8918cb20627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_me(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = dt.datetime.now()\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        print(\n",
    "            f\"Elapsed time of block {func.__name__!r}: {dt.datetime.now() - start_time}\"\n",
    "        )\n",
    "        print(\"-\" * 50)\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------Executable Blocks----------------------------------------------\n",
    "@time_me\n",
    "def DATA_BLOCK(\n",
    "    symbol,\n",
    "    FORCE,\n",
    "    ticker_path,\n",
    "    ohlcv_file,\n",
    "    SAVE,\n",
    "    start_date,\n",
    "    freq,\n",
    "    MAX_INDICATOR_WINDOW,\n",
    "    TIMEFRAME,\n",
    "    market_data_adress,\n",
    "    query_id,\n",
    "    drop_weekends=True,\n",
    "):\n",
    "    print(f\">>> START: DATA BLOCK {symbol}\")\n",
    "\n",
    "    os.makedirs(f\"{ticker_path}/\", exist_ok=True)\n",
    "    # os.makedirs(f\"{ticker_path}/models/\", exist_ok=True)\n",
    "    # os.makedirs(f\"{ticker_path}/optimized_indicators_params/\", exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(f\"{ticker_path}log.txt\"):\n",
    "        with open(f\"{ticker_path}log.txt\", \"w\"):\n",
    "            pass\n",
    "\n",
    "    file_exists = check_existance_of_file(\n",
    "        path_to_file=ticker_path, file_name=ohlcv_file\n",
    "    )\n",
    "\n",
    "    if file_exists and not FORCE[\"OHLCV\"]:\n",
    "        print(\n",
    "            f\"The data is available, {FORCE['OHLCV']}, so the data will simply be read from the file {ticker_path+ohlcv_file}\"\n",
    "        )\n",
    "        ohlcv = pd.read_csv(\n",
    "            ticker_path + ohlcv_file,\n",
    "            parse_dates=[\"timestamp\"],\n",
    "            dayfirst=True,\n",
    "            index_col=[\"timestamp\"],\n",
    "            sep=\";\",\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f\">>> DOWNLOADING {symbol}...\")\n",
    "        history_length = create_history_length(start_date, freq, drop_weekends)\n",
    "        ohlcv = EK_get_ohlcv(\n",
    "            symbol=symbol,\n",
    "            history_length=history_length,\n",
    "            date=start_date,\n",
    "            MAX_INDICATOR_WINDOW=MAX_INDICATOR_WINDOW,\n",
    "            TIMEFRAME=TIMEFRAME,\n",
    "            address=market_data_adress,\n",
    "            query_id=query_id,\n",
    "        )\n",
    "\n",
    "    ohlcv = ohlcv[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "    if SAVE[\"OHLCV\"]:\n",
    "        print(f\">>> SAVING OHLCV {symbol} ...\")\n",
    "        ohlcv.to_csv(ticker_path + ohlcv_file, sep=\";\")\n",
    "        print(f\">>> SAVING OHLCV {symbol} ... DONE\")\n",
    "\n",
    "    print(f\">>> DONE: DATA BLOCK {symbol}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return ohlcv\n",
    "\n",
    "\n",
    "@time_me\n",
    "def DATES_GRID_BLOCK(\n",
    "    symbol, ohlcv, relearn_duration, trade_duration, required_n_of_periods\n",
    "):\n",
    "    print(f\">>> START: DATES GRID BLOCK {symbol}\")\n",
    "\n",
    "    relearner_dates_grid = create_relearner_dates_grid(\n",
    "        ohlcv, relearn_duration, trade_duration\n",
    "    )\n",
    "    print(\"The date grid for retraining is ready..\")\n",
    "\n",
    "    trade_dates_grid = create_trade_dates_grid(relearner_dates_grid, ohlcv)\n",
    "    print(\"The date grid for trading is ready.\")\n",
    "\n",
    "    backtest_IS_start_timestamp, backtest_IS_end_timestamp = (\n",
    "        trade_dates_grid.iloc[0][\"entries\"],\n",
    "        trade_dates_grid.iloc[required_n_of_periods - 1][\"outs\"],\n",
    "    )\n",
    "    print(\n",
    "        f\"The dates that mark the start and end of the first In-Sample stage.: {backtest_IS_start_timestamp, backtest_IS_end_timestamp}\"\n",
    "    )\n",
    "\n",
    "    backtest_OOS_start_timestamp = trade_dates_grid.iloc[required_n_of_periods][\n",
    "        \"entries\"\n",
    "    ]\n",
    "    print(\n",
    "        f\"The date from which 'live trading' starts.: {backtest_OOS_start_timestamp}\"\n",
    "    )\n",
    "\n",
    "    print(f\">>> DONE: DATES GRID BLOCK {symbol}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return (\n",
    "        relearner_dates_grid,\n",
    "        trade_dates_grid,\n",
    "        backtest_IS_start_timestamp,\n",
    "        backtest_IS_end_timestamp,\n",
    "        backtest_OOS_start_timestamp,\n",
    "    )\n",
    "\n",
    "\n",
    "def join_time_pair(dates_grid, separetor=\" \"):\n",
    "\n",
    "    return dates_grid.astype(str).apply(separetor.join, axis=1)\n",
    "\n",
    "\n",
    "@time_me\n",
    "def create_time_labels(relearner_dates_grid, trade_dates_grid, separetor=\" \"):\n",
    "    \"\"\"\n",
    "    Creates a list of date-names for files.\n",
    "    \"\"\"\n",
    "\n",
    "    relearn_time_labels = join_time_pair(relearner_dates_grid, separetor=\" \")\n",
    "    trade_time_labels = join_time_pair(trade_dates_grid, separetor=\" \")\n",
    "\n",
    "    relearn_to_trade_map = {\n",
    "        el_1: el_2\n",
    "        for el_1, el_2 in pd.concat(\n",
    "            [relearn_time_labels, trade_time_labels], axis=1\n",
    "        ).to_numpy()\n",
    "    }\n",
    "\n",
    "    trade_to_relearn_map = {\n",
    "        el_1: el_2\n",
    "        for el_1, el_2 in pd.concat(\n",
    "            [trade_time_labels, relearn_time_labels], axis=1\n",
    "        ).to_numpy()\n",
    "    }\n",
    "\n",
    "    return (\n",
    "        relearn_time_labels,\n",
    "        trade_time_labels,\n",
    "        relearn_to_trade_map,\n",
    "        trade_to_relearn_map,\n",
    "    )\n",
    "\n",
    "\n",
    "@time_me\n",
    "def TARGET_BLOCK(\n",
    "    ohlcv,\n",
    "    symbol,\n",
    "    FORCE,\n",
    "    SAVE,\n",
    "    ticker_path,\n",
    "    target_file,\n",
    "    relearner_dates_grid,\n",
    "    relearn_time_labels,\n",
    "    n_of_candles_to_add_to_target,\n",
    "    trend_side,\n",
    "):\n",
    "    print(f\">>> START: TARGET BLOCK {symbol}\")\n",
    "\n",
    "    os.makedirs(f\"{ticker_path}\", exist_ok=True)\n",
    "    file_exists = check_existance_of_file(\n",
    "        path_to_file=ticker_path, file_name=target_file\n",
    "    )\n",
    "    # ? If the target is already calculated and there's no need to recalculate it.\n",
    "    if file_exists and not FORCE[\"TARGET\"]:\n",
    "        print(\n",
    "            f\"The data is available, {FORCE['TARGET']=}, so it will simply be read from the file {ticker_path+target_file}\"\n",
    "        )\n",
    "        targeted_df = pd.read_csv(\n",
    "            ticker_path + target_file, index_col=[0], parse_dates=[0], sep=\";\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\">>> CALCULATING TARGET {symbol}...\")\n",
    "        parts_targeted_dfs = []\n",
    "        for relearn_entry, relearn_out in relearner_dates_grid.to_numpy():\n",
    "            target_entry, target_out = (\n",
    "                ohlcv.index.to_series()\n",
    "                .shift(n_of_candles_to_add_to_target)\n",
    "                .loc[relearn_entry],  #! <--- comma\n",
    "                relearn_out,\n",
    "            )\n",
    "\n",
    "            # ? Labeling the target.\n",
    "            # parts_targeted_dfs.append(\n",
    "            #     fe.mark_target_new(\n",
    "            #         ohlcv.loc[target_entry:target_out],\n",
    "            #         ticker_path,\n",
    "            #         p.adjClose,\n",
    "            #         **p.target_params,\n",
    "            #     )\n",
    "            # )\n",
    "\n",
    "            period_ohlcv = ohlcv.loc[target_entry:target_out]\n",
    "            mix_target = cook_mix_target(period_ohlcv)\n",
    "\n",
    "            trend_side_target = mix_target[trend_side]\n",
    "            # trend_side_target.name = relearn_time_labels\n",
    "            parts_targeted_dfs.append(trend_side_target)\n",
    "\n",
    "        targeted_df = pd.concat(parts_targeted_dfs, axis=1, keys=relearn_time_labels)\n",
    "\n",
    "        if SAVE[\"TARGET\"]:\n",
    "            print(f\">>> SAVING TARGET {symbol}\")\n",
    "            targeted_df.to_csv(ticker_path + target_file, sep=\";\")\n",
    "\n",
    "    print(f\">>> DONE: TARGET BLOCK {symbol}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return targeted_df\n",
    "\n",
    "\n",
    "@time_me\n",
    "def INDICATORS_BLOCK(\n",
    "    symbol,\n",
    "    FORCE,\n",
    "    SAVE,\n",
    "    ticker_path,\n",
    "    indicators_file,\n",
    "    relearner_dates_grid,\n",
    "    relearn_time_labels,\n",
    "    trade_dates_grid,\n",
    "    targeted_df,\n",
    "    ohlcv,\n",
    "    MAX_INDICATOR_WINDOW,\n",
    "):\n",
    "    print(f\">>> START: INDICATORS BLOCK {symbol}\")\n",
    "\n",
    "    os.makedirs(f\"{ticker_path}/optimized_indicators_params/\", exist_ok=True)\n",
    "\n",
    "    parts_indicators_df = []\n",
    "\n",
    "    for i in range(relearner_dates_grid.shape[0]):\n",
    "\n",
    "        indicators_optimized_params_folder = f\"optimized_indicators_params/{relearn_time_labels.iloc[i].replace(':', '_')}/\"\n",
    "\n",
    "        os.makedirs(\n",
    "            rf\"{ticker_path}/{indicators_optimized_params_folder}\", exist_ok=True\n",
    "        )\n",
    "\n",
    "        file_exists = check_existance_of_file(\n",
    "            path_to_file=f\"{ticker_path}/{indicators_optimized_params_folder}\",\n",
    "            file_name=indicators_file,\n",
    "        )\n",
    "\n",
    "        if file_exists and not FORCE[\"INDICATORS\"]:\n",
    "            print(\n",
    "                f\"The data is available, {FORCE['INDICATORS']=}, so the data will simply be read from the file {ticker_path}/{indicators_optimized_params_folder}{indicators_file}\"\n",
    "            )\n",
    "            indicators_part_df = pd.read_csv(\n",
    "                ticker_path + indicators_optimized_params_folder + indicators_file,\n",
    "                sep=\";\",\n",
    "                index_col=0,\n",
    "                parse_dates=[0],\n",
    "                dayfirst=True,\n",
    "            )\n",
    "            parts_indicators_df.append(indicators_part_df)\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(f\">>> CALCULATING INDICATORS {symbol}...\")\n",
    "\n",
    "            relearn_entry, relearn_out = relearner_dates_grid.iloc[i]\n",
    "            trade_entry, trade_out = trade_dates_grid.iloc[i]\n",
    "            indicators_entry_IS, indicators_out_IS = (\n",
    "                ohlcv.index.to_series()\n",
    "                .shift(MAX_INDICATOR_WINDOW)\n",
    "                .loc[relearn_entry],  #! <--- comma\n",
    "                relearn_out,\n",
    "            )\n",
    "\n",
    "            indicators_entry_OOS, indicators_out_OOS = (\n",
    "                ohlcv.index.to_series()\n",
    "                .shift(MAX_INDICATOR_WINDOW)\n",
    "                .loc[trade_entry],  #! <--- comma\n",
    "                trade_out,\n",
    "            )\n",
    "\n",
    "            if (\n",
    "                str(relearn_entry)\n",
    "                + \" \"\n",
    "                + str(relearn_out)\n",
    "                != relearn_time_labels.iloc[i]\n",
    "            ):\n",
    "                input(\n",
    "                    \"The dates and labels don't match, there might be an error. Submit at your own risk.\"\n",
    "                )\n",
    "\n",
    "            print(f\"INDICATORS {relearn_entry, trade_out} CALCULATING...\")\n",
    "\n",
    "\n",
    "            ohlcv_for_indicators_IS = ohlcv.loc[indicators_entry_IS:indicators_out_IS]\n",
    "            target_for_indicators_IS = targeted_df[relearn_time_labels.iloc[i]].dropna()\n",
    "\n",
    "            df_for_indicators_IS = pd.concat(\n",
    "                [ohlcv_for_indicators_IS, target_for_indicators_IS], axis=1\n",
    "            )\n",
    "            df_for_indicators_IS.columns = [\n",
    "                \"open\",\n",
    "                \"high\",\n",
    "                \"low\",\n",
    "                \"close\",\n",
    "                \"volume\",\n",
    "                \"target\",\n",
    "            ]\n",
    "\n",
    "            indicators_part_df = fe.generate_indis_new(\n",
    "                df_for_indicators_IS,\n",
    "                ticker_path,\n",
    "                df_OOS=ohlcv.loc[indicators_entry_OOS:indicators_out_OOS],\n",
    "                optimize_results_folder=indicators_optimized_params_folder,\n",
    "                optimization=OPTIMIZE_INDICATORS,\n",
    "                MAX_INDICATOR_WINDOW=1000,\n",
    "            ).loc[\n",
    "                relearn_entry:\n",
    "            ]\n",
    "\n",
    "            parts_indicators_df.append(indicators_part_df)\n",
    "\n",
    "            if SAVE[\"INDICATORS\"]:\n",
    "                indicators_part_df.to_csv(\n",
    "                    f\"{ticker_path}/{indicators_optimized_params_folder}{indicators_file}\",\n",
    "                    sep=\";\",\n",
    "                )\n",
    "            print(f\"INDICATORS {relearn_entry, trade_out} ... DONE\")\n",
    "\n",
    "    indicators_df = pd.concat(parts_indicators_df, axis=1, keys=relearn_time_labels)\n",
    "\n",
    "    return indicators_df\n",
    "\n",
    "\n",
    "@time_me\n",
    "def MODELS_BLOCK(\n",
    "    symbol,\n",
    "    relearner_dates_grid,\n",
    "    trade_dates_grid,\n",
    "    relearn_time_labels,\n",
    "    current_libraries,\n",
    "    ticker_path,\n",
    "    FORCE,\n",
    "    SAVE,\n",
    "    possible_function_to_call_READ_MODELS,\n",
    "    possible_function_to_call_TRAIN,\n",
    "    indicators_df,\n",
    "    targeted_df,\n",
    "):\n",
    "    os.makedirs(f\"{ticker_path}/models/\", exist_ok=True)\n",
    "    print(f\">>> START: MODELS BLOCK {symbol}\")\n",
    "    predicted_df_parts = []  # ? Here we will store pieces of the predicted_df.\n",
    "\n",
    "    calculated_predicted_df = check_existance_of_file(\n",
    "        path_to_file=ticker_path, file_name=\"predicted_df.csv\"\n",
    "    )\n",
    "\n",
    "    for i in range(relearner_dates_grid.shape[0]):\n",
    "        # ? Determining the dates we need to focus on.\n",
    "        relearn_entry, relearn_out = relearner_dates_grid.iloc[i]\n",
    "        current_date_range = relearn_time_labels.iloc[\n",
    "            i\n",
    "        ]  # The name of the column to lock onto.\n",
    "        current_date_range_path = current_date_range.replace(\":\", \"_\")\n",
    "        os.makedirs(\n",
    "            ticker_path + f\"models/{current_date_range_path}/PC/\", exist_ok=True\n",
    "        )\n",
    "        # os.makedirs(ticker_path + f\"models/{current_date_range_path}/AG/\", exist_ok=True)\n",
    "\n",
    "        calculated_models = True\n",
    "        for library in current_libraries:\n",
    "            for model in current_models[library]:\n",
    "                if not os.path.exists(\n",
    "                    ticker_path\n",
    "                    + f\"models/{current_date_range_path}/{library}/models/{model}/model.pkl\"\n",
    "                ):\n",
    "                    calculated_models = False\n",
    "\n",
    "        if (\n",
    "            calculated_models and not FORCE[\"MODELS_TRAIN\"]\n",
    "        ):  \n",
    "            print(\n",
    "                f\"All models for the symbol {symbol} and the time interval {current_date_range} are available and stored in their respective locations; they just need to be read.\"\n",
    "            )\n",
    "            if calculated_predicted_df and not FORCE[\"MODELS_TEST\"]:\n",
    "                print(\n",
    "                    f\"Since predicted_df for symbol {symbol} exists and {FORCE['MODELS_TEST']} is true, we don't even need to read the models.\"\n",
    "                )\n",
    "                predicted_df = pd.read_csv(\n",
    "                    ticker_path + \"predicted_df.csv\",\n",
    "                    sep=\";\",\n",
    "                    index_col=[0],\n",
    "                    parse_dates=[0],\n",
    "                    dayfirst=True,\n",
    "                    header=[0, 1],\n",
    "                )\n",
    "\n",
    "                return predicted_df\n",
    "\n",
    "            elif os.path.exists(\n",
    "                ticker_path + f\"models/{current_date_range_path}/predicted_part_df.csv\"\n",
    "            ):\n",
    "                predicted_df_part = pd.read_csv(\n",
    "                    ticker_path\n",
    "                    + f\"models/{current_date_range_path}/predicted_part_df.csv\",\n",
    "                    sep=\";\",\n",
    "                    parse_dates=[0],\n",
    "                    header=[0, 1],\n",
    "                    index_col=[0],\n",
    "                    dayfirst=True,\n",
    "                )\n",
    "                predicted_df_parts.append(predicted_df_part)\n",
    "\n",
    "                continue\n",
    "            else:\n",
    "                print(f\">>> READING MODELS {symbol} за {current_date_range} ...\")\n",
    "                trained_models = md.READ_MODELS(\n",
    "                    ticker_path,\n",
    "                    current_date_range_path,\n",
    "                    current_libraries,\n",
    "                    possible_function_to_call_READ_MODELS,\n",
    "                )\n",
    "                print(f\">>> READING MODELS {symbol} за {current_date_range} ... DONE\")\n",
    "        else:\n",
    "            print(f\">>> MODELS TRAIN {symbol}, {current_date_range} ...\")\n",
    "            current_date_range_indicators = (\n",
    "                indicators_df[current_date_range]\n",
    "                .dropna()\n",
    "                .rename(lambda x: str(x), axis=1)\n",
    "                .rename_axis(\"timestamp\")\n",
    "            )\n",
    "            current_date_range_indicators = current_date_range_indicators.loc[\n",
    "                relearn_entry:relearn_out\n",
    "            ]\n",
    "\n",
    "            df_for_train_models = np.round(\n",
    "                pd.concat(\n",
    "                    [\n",
    "                        targeted_df[current_date_range].dropna().rename(\"target\"),\n",
    "                        current_date_range_indicators,\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                ),\n",
    "                10,\n",
    "            )\n",
    "\n",
    "            trained_models = md.TRAIN(\n",
    "                df_for_train_models,\n",
    "                ticker_path,\n",
    "                current_date_range_path,\n",
    "                current_libraries,\n",
    "                possible_function_to_call_TRAIN,\n",
    "                cv_pct=0.2,\n",
    "                label=\"target\",\n",
    "            )\n",
    "            print(f\">>> MODELS TRAIN {symbol}, {current_date_range} ... DONE\")\n",
    "\n",
    "        test_entry, test_out = trade_dates_grid.iloc[i]\n",
    "\n",
    "        test_current_date_range_indicators = (\n",
    "            indicators_df[current_date_range]\n",
    "            .dropna()\n",
    "            .rename(lambda x: str(x), axis=1)\n",
    "            .rename_axis(\"timestamp\")\n",
    "        )\n",
    "        test_current_date_range_indicators = np.round(\n",
    "            test_current_date_range_indicators.loc[test_entry:test_out], 10\n",
    "        )\n",
    "\n",
    "        predicted_df_part = md.TEST(\n",
    "            trained_models,\n",
    "            possible_function_to_call_TEST,\n",
    "            test_current_date_range_indicators,\n",
    "        )\n",
    "        predicted_df_parts.append(predicted_df_part)\n",
    "\n",
    "    predicted_df = pd.concat(predicted_df_parts)\n",
    "\n",
    "    predicted_df.to_csv(ticker_path + \"predicted_df.csv\", sep=\";\")\n",
    "\n",
    "    print(f\">>> DONE: MODELS BLOCK {symbol}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return predicted_df\n",
    "\n",
    "\n",
    "def cook_mix_target(ohlcv):\n",
    "    close = ohlcv[\"close\"]\n",
    "    width = 1\n",
    "    distance = 1\n",
    "    wlen = 24\n",
    "    prominence = close.rolling(3).std().bfill().values\n",
    "    prominence = np.where(prominence < 0.0005, 0.0005, prominence)\n",
    "\n",
    "    peaks, _ = find_peaks(\n",
    "        close, width=width, distance=distance, prominence=prominence, wlen=wlen\n",
    "    )\n",
    "    valley, _ = find_peaks(\n",
    "        -close, width=width, distance=distance, prominence=prominence, wlen=wlen\n",
    "    )\n",
    "    long = pd.DataFrame(\n",
    "        [1] * len(close[peaks]), columns=[\"long\"], index=close[peaks].index\n",
    "    )\n",
    "    short = pd.DataFrame(\n",
    "        [1] * len(close[valley]), columns=[\"short\"], index=close[valley].index\n",
    "    )\n",
    "\n",
    "    mix_target = pd.concat([close, long, short], axis=1).fillna(0)\n",
    "    return mix_target\n",
    "\n",
    "\n",
    "def adjust_target(simple_target, target):\n",
    "    adjusted_target = pd.DataFrame()\n",
    "    for column in target.columns:\n",
    "        new_column = simple_target.loc[target.loc[:, column].dropna().index]\n",
    "        new_column.name = column\n",
    "        adjusted_target = pd.concat([adjusted_target, new_column], axis=1)\n",
    "    return adjusted_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0b0c1-f9be-479d-9a12-37ceb516247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(symbol):\n",
    "\n",
    "    ticker_path = TICKERS_PATH + symbol + \"/\"\n",
    "    # fetching the data.\n",
    "    ohlcv = DATA_BLOCK(\n",
    "        symbol,\n",
    "        FORCE,\n",
    "        ticker_path,\n",
    "        ohlcv_file,\n",
    "        SAVE,\n",
    "        start_date,\n",
    "        freq,\n",
    "        MAX_INDICATOR_WINDOW,\n",
    "        TIMEFRAME,\n",
    "        market_data_adress,\n",
    "        query_id,\n",
    "        drop_weekends=False,\n",
    "    )\n",
    "\n",
    "    # creating a grid of timestamps.\n",
    "    (\n",
    "        relearner_dates_grid,\n",
    "        trade_dates_grid,  # Grids of dates for retraining and trading.\n",
    "        backtest_IS_start_timestamp,\n",
    "        backtest_IS_end_timestamp,  # Timestamps for the start and end of the first iteration of In-Sample (IS) phase.\n",
    "        backtest_OOS_start_timestamp,  # The timestamp of the beginning of Out-of-Sample (OOS) phase.\n",
    "    ) = DATES_GRID_BLOCK(\n",
    "        symbol,\n",
    "        ohlcv.iloc[MAX_INDICATOR_WINDOW:],\n",
    "        relearn_duration,\n",
    "        trade_duration,\n",
    "        required_n_of_periods,\n",
    "    )\n",
    "    print(relearner_dates_grid)\n",
    "\n",
    "    # creating labels from timestamps and mapping them bijectively to each other.\n",
    "    (\n",
    "        relearn_time_labels,\n",
    "        trade_time_labels,\n",
    "        relearn_to_trade_map,\n",
    "        trade_to_relearn_map,\n",
    "    ) = create_time_labels(relearner_dates_grid, trade_dates_grid, separetor=\" \")\n",
    "\n",
    "    for trend_side in [\"long\", \"short\"]:\n",
    "        ticker_path = TICKERS_PATH + symbol + \"/\" + trend_side + \"/\"\n",
    "\n",
    "        # labeling the target\n",
    "        targeted_df = TARGET_BLOCK(\n",
    "            ohlcv,\n",
    "            symbol,\n",
    "            FORCE,\n",
    "            SAVE,\n",
    "            ticker_path,\n",
    "            target_file,\n",
    "            relearner_dates_grid,\n",
    "            relearn_time_labels,\n",
    "            n_of_candles_to_add_to_target,\n",
    "            trend_side,\n",
    "        )\n",
    "\n",
    "        indicators_df = INDICATORS_BLOCK(\n",
    "            symbol,\n",
    "            FORCE,\n",
    "            SAVE,\n",
    "            ticker_path,\n",
    "            indicators_file,\n",
    "            relearner_dates_grid,\n",
    "            relearn_time_labels,\n",
    "            trade_dates_grid,\n",
    "            targeted_df,\n",
    "            ohlcv,\n",
    "            MAX_INDICATOR_WINDOW,\n",
    "        )\n",
    "\n",
    "        predicted_df = MODELS_BLOCK(\n",
    "            symbol,\n",
    "            relearner_dates_grid,\n",
    "            trade_dates_grid,\n",
    "            relearn_time_labels,\n",
    "            current_libraries,\n",
    "            ticker_path,\n",
    "            FORCE,\n",
    "            SAVE,\n",
    "            possible_function_to_call_READ_MODELS,\n",
    "            possible_function_to_call_TRAIN,\n",
    "            indicators_df,\n",
    "            targeted_df,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec1e93-9738-4fc9-93e5-6a73893b11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in symbols:\n",
    "    main(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2861f1-3a34-4cc0-a844-d37d0392a863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret3",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
